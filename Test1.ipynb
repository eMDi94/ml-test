{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python==3.4.5.20 in /home/ec2-user/.local/lib/python3.6/site-packages (3.4.5.20)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from opencv-contrib-python==3.4.5.20) (1.17.4)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --user opencv-contrib-python==3.4.5.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutSaltPepperNoise(edgeImg):\n",
    "    # Get rid of salt & pepper noise.\n",
    "    count = 0\n",
    "    lastMedian = edgeImg\n",
    "    median = cv2.medianBlur(edgeImg, 3)\n",
    "    while not np.array_equal(lastMedian, median):\n",
    "        # get those pixels that gets zeroed out\n",
    "        zeroed = np.invert(np.logical_and(median, edgeImg))\n",
    "        edgeImg[zeroed] = 0\n",
    "\n",
    "        count = count + 1\n",
    "        if count > 70:\n",
    "            break\n",
    "        lastMedian = median\n",
    "        median = cv2.medianBlur(edgeImg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSignificantContour(edgeImg):\n",
    "    image, contours, hierarchy = cv2.findContours(\n",
    "        edgeImg,\n",
    "        cv2.RETR_TREE,\n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    # Find level 1 contours\n",
    "    level1Meta = []\n",
    "    for contourIndex, tupl in enumerate(hierarchy[0]):\n",
    "        # Each array is in format (Next, Prev, First child, Parent)\n",
    "        # Filter the ones without parent\n",
    "        if tupl[3] == -1:\n",
    "            tupl = np.insert(tupl.copy(), 0, [contourIndex])\n",
    "            level1Meta.append(tupl)\n",
    "    # From among them, find the contours with large surface area.\n",
    "    contoursWithArea = []\n",
    "    for tupl in level1Meta:\n",
    "        contourIndex = tupl[0]\n",
    "        contour = contours[contourIndex]\n",
    "        area = cv2.contourArea(contour)\n",
    "        contoursWithArea.append([contour, area, contourIndex])\n",
    "\t\t\n",
    "    contoursWithArea.sort(key=lambda meta: meta[1], reverse=True)\n",
    "    largestContour = contoursWithArea[0][0]\n",
    "    return largestContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('sample1.jpg', 1)\n",
    "blurred = cv2.GaussianBlur(src, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurred_float = blurred.astype(np.float32) / 255.0\n",
    "edgeDetector = cv2.ximgproc.createStructuredEdgeDetection(\"model.yml\")\n",
    "edges = edgeDetector.detectEdges(blurred_float) * 255.0\n",
    "cv2.imwrite('target/edge-raw.jpg', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_8u = np.asarray(edges, np.uint8)\n",
    "filterOutSaltPepperNoise(edges_8u)\n",
    "cv2.imwrite('target/edge.jpg', edges_8u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contour = findSignificantContour(edges_8u)\n",
    "# Draw the contour on the original image\n",
    "contourImg = np.copy(src)\n",
    "cv2.drawContours(contourImg, [contour], 0, (0, 255, 0), 2, cv2.LINE_AA, maxLevel=1)\n",
    "cv2.imwrite('target/contour.jpg', contourImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros_like(edges_8u)\n",
    "cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "# calculate sure foreground area by dilating the mask\n",
    "mapFg = cv2.erode(mask, np.ones((5, 5), np.uint8), iterations=10)\n",
    "\n",
    "# mark inital mask as \"probably background\"\n",
    "# and mapFg as sure foreground\n",
    "trimap = np.copy(mask)\n",
    "trimap[mask == 0] = cv2.GC_BGD\n",
    "trimap[mask == 255] = cv2.GC_PR_BGD\n",
    "trimap[mapFg == 255] = cv2.GC_FGD\n",
    "\n",
    "# visualize trimap\n",
    "trimap_print = np.copy(trimap)\n",
    "trimap_print[trimap_print == cv2.GC_PR_BGD] = 128\n",
    "trimap_print[trimap_print == cv2.GC_FGD] = 255\n",
    "cv2.imwrite('target/trimap.png', trimap_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run grabcut\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "rect = (0, 0, mask.shape[0] - 1, mask.shape[1] - 1)\n",
    "cv2.grabCut(src, trimap, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "# create mask again\n",
    "mask2 = np.where(\n",
    "    (trimap == cv2.GC_FGD) | (trimap == cv2.GC_PR_FGD),\n",
    "    255,\n",
    "    0\n",
    ").astype('uint8')\n",
    "cv2.imwrite('target/mask2.jpg', mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contour2 = findSignificantContour(mask2)\n",
    "mask3 = np.zeros_like(mask2)\n",
    "cv2.fillPoly(mask3, [contour2], 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blended alpha cut-out\n",
    "mask3 = np.repeat(mask3[:, :, np.newaxis], 3, axis=2)\n",
    "mask4 = cv2.GaussianBlur(mask3, (3, 3), 0)\n",
    "alpha = mask4.astype(float) * 1.1  # making blend stronger\n",
    "alpha[mask3 > 0] = 255\n",
    "alpha[alpha > 255] = 255\n",
    "alpha = alpha.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreground = np.copy(src).astype(float)\n",
    "foreground[mask4 == 0] = 0\n",
    "background = np.ones_like(foreground, dtype=float) * 255\n",
    "\n",
    "cv2.imwrite('target/foreground.png', foreground)\n",
    "cv2.imwrite('target/background.png', background)\n",
    "cv2.imwrite('target/alpha.png', alpha)\n",
    "\n",
    "# Normalize the alpha mask to keep intensity between 0 and 1\n",
    "alpha = alpha / 255.0\n",
    "# Multiply the foreground with the alpha matte\n",
    "foreground = cv2.multiply(alpha, foreground)\n",
    "# Multiply the background with ( 1 - alpha )\n",
    "background = cv2.multiply(1.0 - alpha, background)\n",
    "# Add the masked foreground and background.\n",
    "cutout = cv2.add(foreground, background)\n",
    "\n",
    "cv2.imwrite('target/cutout.jpg', cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('target/cutout.jpg')#image path and name\n",
    "img = img.convert(\"RGBA\")\n",
    "datas = img.getdata()\n",
    "newData = []\n",
    "for item in datas:\n",
    "    if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "        newData.append((255, 255, 255, 0))\n",
    "    else:\n",
    "        newData.append(item)\n",
    "img.putdata(newData)\n",
    "img.save(\"target/cutout.png\", \"PNG\")#converted Image name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
